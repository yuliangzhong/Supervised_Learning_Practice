{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tslearn.neural_network import TimeSeriesMLPRegressor, TimeSeriesMLPClassifier\n",
    "from tslearn.svm import TimeSeriesSVR, TimeSeriesSVC\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sktime.classification.interval_based import TimeSeriesForest\n",
    "from sktime.classification.shapelet_based import MrSEQLClassifier\n",
    "from sktime.transformations.panel.compose import ColumnConcatenator\n",
    "from sktime.regression.compose import TimeSeriesForestRegressor\n",
    "from sktime.utils.data_processing import from_3d_numpy_to_nested\n",
    "\n",
    "train_features = \"train_features.csv\"\n",
    "train_labels = \"train_labels.csv\"\n",
    "test_features = \"test_features.csv\"\n",
    "\n",
    "#data set\n",
    "trainx = np.loadtxt(train_features, delimiter=',', skiprows=1) [:,2:] \n",
    "trainy = np.loadtxt(train_labels, delimiter=',', skiprows=1) [:,1:]\n",
    "\n",
    "testx  = np.loadtxt(test_features, delimiter=',', skiprows=1) [:,2:] \n",
    "testy_1 = pd.read_csv(\"sample.csv\")\n",
    "testy_2 = pd.read_csv(\"sample.csv\")\n",
    "#deal with headers better, change to pd read next time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#simple impute\n",
    "\n",
    "def impute(x ,steps=12):\n",
    "    imputer=SimpleImputer(missing_values=np.nan,strategy='mean')\n",
    "    x_trans=x\n",
    "    \n",
    "    for i in range(x_trans.shape[0]//steps):\n",
    "        \n",
    "        #fill 0 for columns that are all nan\n",
    "        for j in range(x_trans.shape[1]):\n",
    "            if np.all(np.isnan(x_trans[i*12:i*12+12,j])):\n",
    "                x_trans[i*12:i*12+12,j].fill(0)\n",
    "\n",
    "        imputer=imputer.fit(x_trans[i*12:i*12+12,0:35])\n",
    "        x_trans[i*12:i*12+12,0:35]=imputer.transform(x_trans[i*12:i*12+12,0:35])\n",
    "        #this transform will remove columns with all nan\n",
    "        \n",
    "    return np.array(x_trans)\n",
    "\n",
    "trainx = impute(trainx)\n",
    "testx  = impute(testx)\n",
    "print(trainx.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data rearrange\n",
    "\n",
    "#18995 cases, 15 features(dimensions) and 12 time points\n",
    "#tslearn input format: 3d array (n_samples, n_timesteps, n_dimensions)\n",
    "#sktime input format: nested pd.dataframe, rows->instances cols->dimensions, cells->time series\n",
    "\n",
    "trainx = trainx.reshape((int(trainx.shape[0]/12), 12, trainx.shape[1]))\n",
    "testx  = testx.reshape((int(testx.shape[0]/12), 12, testx.shape[1]))\n",
    "trainx_sk = from_3d_numpy_to_nested(trainx.transpose((0, 2, 1)))\n",
    "testx_sk = from_3d_numpy_to_nested(testx.transpose((0, 2, 1)))\n",
    "#double check with input format....\n",
    "print(trainx.shape)\n",
    "print(trainx_sk.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#classifier\n",
    "steps = [\n",
    "    (\"concatenate\", ColumnConcatenator()),\n",
    "    (\"classify\", TimeSeriesForest(n_estimators=200)),\n",
    "]\n",
    "\n",
    "for i in range(11):\n",
    "    y=trainy[:,i]\n",
    "    #clf = TimeSeriesSVC(C=1.0, kernel=\"gak\",probability=True,class_weight=\"balanced\")\n",
    "    mlp = TimeSeriesMLPClassifier(hidden_layer_sizes=(64, 64),random_state=0)\n",
    "    mlp.fit(trainx, y)\n",
    "    \n",
    "    clf = Pipeline(steps)\n",
    "    clf.fit(trainx_sk, y)\n",
    "\n",
    "    pred_1 = mlp.predict_proba(testx)[:, 1]    \n",
    "    pred_2 = clf.predict_proba(testx_sk)[:, 1]   \n",
    "    #shape(N, k) k classes, for 0 or 1 here\n",
    "    testy_1[testy_1.columns[i+1]] = pred_1\n",
    "    testy_2[testy_2.columns[i+1]] = pred_2\n",
    "    print(\"iteration {} done\".format(i+1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 12 done\n",
      "iteration 13 done\n",
      "iteration 14 done\n",
      "iteration 15 done\n"
     ]
    }
   ],
   "source": [
    "#regressor\n",
    "\n",
    "\n",
    "for i in range(11, 15):\n",
    "    y=trainy[:,i]\n",
    "    mlp = TimeSeriesMLPRegressor(hidden_layer_sizes=(64, 64),learning_rate_init=0.001, max_iter=2000)\n",
    "    mlp.fit(trainx, y)\n",
    "    #clf = TimeSeriesSVR(C=1.0, kernel=\"gak\")\n",
    "\n",
    "    pred_1 = mlp.predict(testx)\n",
    "    #pred_2 = clf.fit(trainx, y).predict(testx)\n",
    "    testy_1[testy_1.columns[i+1]] = pred_1\n",
    "    testy_2[testy_2.columns[i+1]] = pred_1\n",
    "    print(\"iteration {} done\".format(i+1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write data\n",
    "testy_1.to_csv('prediction_nn.csv', index=False, float_format='%.3f')\n",
    "testy_2.to_csv('prediction_sk_tsf.csv', index=False, float_format='%.3f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
